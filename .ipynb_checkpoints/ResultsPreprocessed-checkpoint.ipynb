{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim \n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from collections import Counter \n",
    "from gensim.models import Word2Vec\n",
    "# from googletrans import Translator\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"songs7kFormattedWithCompressions.csv\", encoding = \"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed</th>\n",
       "      <th>songLyrics</th>\n",
       "      <th>songMovie</th>\n",
       "      <th>songSinger</th>\n",
       "      <th>songName</th>\n",
       "      <th>years</th>\n",
       "      <th>compressions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ghoomar rabb waare\\r\\nAap padharo saa\\r\\n\\r\\nA...</td>\n",
       "      <td>Padmaavat</td>\n",
       "      <td>Shreya Ghoshal</td>\n",
       "      <td>Ghoomar</td>\n",
       "      <td>2018</td>\n",
       "      <td>64.734300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yo yo honey singh…\\r\\n\\r\\nHoye…\\r\\n\\r\\nSuno ka...</td>\n",
       "      <td>Sonu Ke Titu ki Sweety</td>\n",
       "      <td>Yo Yo Honey Singh, Simar Kaur &amp; Ishers</td>\n",
       "      <td>Dil Chori</td>\n",
       "      <td>2018</td>\n",
       "      <td>65.985998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Aaj se teri saari galiyan meri ho gayi\\r\\nAaj ...</td>\n",
       "      <td>Padman</td>\n",
       "      <td>Arijit Singh</td>\n",
       "      <td>Aaj Se Teri</td>\n",
       "      <td>2018</td>\n",
       "      <td>65.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Boy you don’t have to be the last one standing...</td>\n",
       "      <td>Sonu Ke Titu Ki Sweety</td>\n",
       "      <td>Zack Knight &amp; Jasmin Walia</td>\n",
       "      <td>Bom Diggy Diggy</td>\n",
       "      <td>2018</td>\n",
       "      <td>66.455696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Pila de.. pila de..\\r\\nPila de pila de\\r\\n\\r\\n...</td>\n",
       "      <td>Sonu Ke Titu ki Sweety</td>\n",
       "      <td>Yo Yo Honey Singh, Neha Kakkar, Navraj Hans</td>\n",
       "      <td>Chhote Chhote Peg Maar</td>\n",
       "      <td>2018</td>\n",
       "      <td>62.760417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unnamed                                         songLyrics  \\\n",
       "0        0  Ghoomar rabb waare\\r\\nAap padharo saa\\r\\n\\r\\nA...   \n",
       "1        1  Yo yo honey singh…\\r\\n\\r\\nHoye…\\r\\n\\r\\nSuno ka...   \n",
       "2        2  Aaj se teri saari galiyan meri ho gayi\\r\\nAaj ...   \n",
       "3        3  Boy you don’t have to be the last one standing...   \n",
       "4        4  Pila de.. pila de..\\r\\nPila de pila de\\r\\n\\r\\n...   \n",
       "\n",
       "                songMovie                                   songSinger  \\\n",
       "0               Padmaavat                               Shreya Ghoshal   \n",
       "1  Sonu Ke Titu ki Sweety       Yo Yo Honey Singh, Simar Kaur & Ishers   \n",
       "2                  Padman                                 Arijit Singh   \n",
       "3  Sonu Ke Titu Ki Sweety                   Zack Knight & Jasmin Walia   \n",
       "4  Sonu Ke Titu ki Sweety  Yo Yo Honey Singh, Neha Kakkar, Navraj Hans   \n",
       "\n",
       "                  songName  years  compressions  \n",
       "0                  Ghoomar   2018     64.734300  \n",
       "1                Dil Chori   2018     65.985998  \n",
       "2              Aaj Se Teri   2018     65.083333  \n",
       "3          Bom Diggy Diggy   2018     66.455696  \n",
       "4   Chhote Chhote Peg Maar   2018     62.760417  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=[]\n",
    "for i in range(data.shape[0]):\n",
    "    try:\n",
    "        doc.append(nltk.word_tokenize(re.sub('[^a-zA-z\\s]','',data['songLyrics'][i].lower())))\n",
    "    except:\n",
    "        doc.append([\"\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[]\n",
    "strr=''\n",
    "for i in doc:\n",
    "    srr=\"\"\n",
    "    for j in i:\n",
    "        srr=srr+' '+j\n",
    "        strr=strr+' '+j\n",
    "    train.append(srr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_lyrics():\n",
    "#     count_vec1=CountVectorizer()\n",
    "#     features1=count_vec1.fit_transform(train)\n",
    "  \n",
    "#     #stemming\n",
    "#     stem3=['ing','ana','yan','ane','eya','ies','aaa','aan','ake']\n",
    "#     stem2=['on','ai','na','an','un','ey','en','se','aa']\n",
    "#     stem1=['a','e','i','o','u','y','n','s']\n",
    "#     dictt={}\n",
    "#     for i in count_vec1.get_feature_names():\n",
    "#         dictt[i]=i\n",
    "    \n",
    "#     allwords=[]\n",
    "#     for i in dictt:\n",
    "#         allwords.append(i)\n",
    "\n",
    "\n",
    "#     for i in range(len(allwords)):\n",
    "#         j=i+1\n",
    "#         while j<len(allwords):\n",
    "#             if len(allwords[i])>3 and (len(allwords[j])-len(allwords[i])==3) and allwords[i]==allwords[j][0:-3] and (allwords[j][-3:] in stem3) and dictt[allwords[j]]==allwords[j]:\n",
    "#                 dictt[allwords[j]]=dictt[allwords[i]]\n",
    "# #                 print(allwords[j],dictt[allwords[i]])\n",
    "\n",
    "#             elif len(allwords[i])>3 and (len(allwords[j])-len(allwords[i])==2) and allwords[i]==allwords[j][0:-2] and (allwords[j][-2:] in stem2) and dictt[allwords[j]]==allwords[j]:\n",
    "#                 dictt[allwords[j]]=dictt[allwords[i]]\n",
    "# #                 print(allwords[j],dictt[allwords[i]])\n",
    "\n",
    "\n",
    "#             elif len(allwords[i])>3 and (len(allwords[j])-len(allwords[i])==1) and allwords[i]==allwords[j][0:-1] and (allwords[j][-1] in stem1) and dictt[allwords[j]]==allwords[j]:\n",
    "#                 dictt[allwords[j]]=dictt[allwords[i]]\n",
    "# #                 print(allwords[j],dictt[allwords[i]])\n",
    "#             j=j+1\n",
    "\n",
    "#     afterstemming=[]\n",
    "#     for i in dictt:\n",
    "#         afterstemming.append(dictt[i])\n",
    "#     afterstemming=set(afterstemming)\n",
    "#     print('length after stemming', len(afterstemming))\n",
    "    \n",
    "#     stemdictt={}\n",
    "#     for i in dictt:\n",
    "#         stemdictt[dictt[i]]=dictt[i]\n",
    "    \n",
    "#     #spelling errors\n",
    "#     for i in afterstemming:\n",
    "#         if 'aa' in i:\n",
    "#             word=i.replace('aa','a')\n",
    "#             if word in afterstemming:\n",
    "#                 stemdictt[i]=word\n",
    "\n",
    "#         if 'ee' in i:\n",
    "#             word=i.replace('ee','i')\n",
    "#             if word in afterstemming:\n",
    "#                 stemdictt[i]=word\n",
    "\n",
    "#         if 'w' in i:\n",
    "#             word=i.replace('w','v')\n",
    "#             if word in afterstemming:\n",
    "#                 stemdictt[i]=word\n",
    "\n",
    "#         if 'j' in i:\n",
    "#             word=i.replace('j','z')\n",
    "#             if word in afterstemming:\n",
    "#                 stemdictt[i]=word\n",
    "\n",
    "#         if 'oo' in i:\n",
    "#             word=i.replace('oo','u')\n",
    "#             if word in afterstemming:\n",
    "#                 stemdictt[i]=word\n",
    "# #         if stemdictt[i]!=i:\n",
    "# #             print(i, stemdictt[i])\n",
    "            \n",
    "#     afterspell=[]\n",
    "    \n",
    "#     for i in stemdictt:\n",
    "#         afterspell.append(stemdictt[i])\n",
    "#     afterspell=set(afterspell)\n",
    "#     print('length after spell', len(afterspell))\n",
    "    \n",
    "    \n",
    "#     for i in dictt:\n",
    "#         dictt[i]=stemdictt[dictt[i]]\n",
    "#     return dictt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_d=preprocess_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocab_d))\n",
    "vocab_d['chhori']='chhori'\n",
    "vocab_d['munda']='munda'\n",
    "vocab_d['mundey']='mundey'\n",
    "vocab_d['chhora']='chhora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "docp is preprocessed documents list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docp=[]\n",
    "for i in range(len(doc)):\n",
    "    k=[]\n",
    "    for j in range(len(doc[i])):\n",
    "        if doc[i][j] in vocab_d:\n",
    "            k.append(vocab_d[doc[i][j]])\n",
    "        else:\n",
    "            k.append(doc[i][j])\n",
    "#         print(vocab_d[doc[i][j]])\n",
    "    docp.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_names=['ladki','girl','gori','lady','kudi','chhori','woman']\n",
    "male_names=['ladka','munda','mundey','boy','chokra','chhora','man']\n",
    "\n",
    "color =['sanwali','saanwala','pink','pinky','red','laal','kaala','kaali','gori','gora','white','black','yellow','brown']\n",
    "softAttitude=['bholi','bhola','komalkomal','heeran','hirni','nadaan','beautiful','mastani','mastana','seedhi','seedha','sharmili','sharmeela','sohni','sohna','bhali','bhala']\n",
    "strongAttitude=['kukkad','bigda','bigdi','khatra','khauf','handa','jungli','badmash','gussa']\n",
    "cars=['car', 'gaddi','drive','lamborghini','jaguar','gaadi','motorcycle']\n",
    "clothes=['jeans','skirt','shirt','lehnga','chunni','ainak','ghagra','kurta','pajama','jacket','choodi','jhumka','chasma','chashma','kangan','top']\n",
    "food=['namkeen','mithi','tikhi','teekha','khatti','makkhan','sweet','nimbu','imli','mitthe','rasmalai','mirchi','mishti','naariyal']\n",
    "alcohol=['daaru','whisky','daru','pila','botal','peg','shots','drink','peeta']\n",
    "bodylooks=['choti','chota','cheeks','adayein','thumka','aankhen','aankhein','nazron','charming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att1=[color,softAttitude,strongAttitude,cars, clothes,food,alcohol,bodylooks]\n",
    "\n",
    "attp=[]\n",
    "for i in range(len(att1)):\n",
    "    k=[]\n",
    "    for j in range(len(att1[i])):\n",
    "        if att1[i][j] in vocab_d:\n",
    "            k.append(vocab_d[att1[i][j]])\n",
    "        else:\n",
    "            k.append(att1[i][j])\n",
    "    attp.append(list(set(k)))\n",
    "color =attp[0]\n",
    "softAttitude=attp[1]\n",
    "strongAttitude=attp[2]\n",
    "cars=attp[3]\n",
    "clothes=attp[4]\n",
    "food=attp[5]\n",
    "alcohol=attp[6]\n",
    "bodylooks=attp[7]\n",
    "att1=[color,softAttitude,strongAttitude,cars, clothes,food,alcohol,bodylooks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weat Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weat_test(target_one,target_two, target_one_words, attribute_one,attribute_two, attribute_one_words, target_two_words, attribute_two_words):\n",
    "    cos=[]\n",
    "    s=0\n",
    "    s1=[]\n",
    "    s2=[]\n",
    "    S=[]\n",
    "    n=0\n",
    "    for i in range(0, len(target_one_words)):\n",
    "            c1=[]\n",
    "            c2=[]\n",
    "            for k in range(0, len(attribute_one_words)):\n",
    "                wt = target_one_words[i]\n",
    "                at1 = attribute_one_words[k]\n",
    "                try:\n",
    "                    cos1= model.wv.similarity(wt, at1)\n",
    "                    cos.append(cos1)\n",
    "                    c1.append(cos1)\n",
    "                except:\n",
    "                    cos1=0\n",
    "                    cos.append(cos1)\n",
    "                    c1.append(cos1)\n",
    "                    continue\n",
    "            for k in range(0, len(attribute_two_words)):\n",
    "                cos2=0\n",
    "                wt = target_one_words[i]\n",
    "                at2 = attribute_two_words[k]\n",
    "                try:\n",
    "                    cos2= model.wv.similarity(wt, at2)\n",
    "                    cos.append(cos2)\n",
    "                    c2.append(cos2)\n",
    "                except:\n",
    "                    cos2=0\n",
    "                    cos.append(cos2)\n",
    "                    c2.append(cos2)\n",
    "                    continue\n",
    "            s1.append((np.mean(c1)-np.mean(c2)))\n",
    "            S.append((np.mean(c1)-np.mean(c2)))\n",
    "            n=n+1\n",
    "    for i in range(0, len(target_two_words)):\n",
    "            c1=[]\n",
    "            c2=[]\n",
    "            for k in range(0, len(attribute_one_words)):\n",
    "                wt = target_two_words[i]\n",
    "                at1 = attribute_one_words[k]\n",
    "                try:\n",
    "                    cos1= model.wv.similarity(wt, at1)\n",
    "                    cos.append(cos1)\n",
    "                    c1.append(cos1)\n",
    "                except:\n",
    "                    cos1=0\n",
    "                    cos.append(cos1)\n",
    "                    c1.append(cos1)\n",
    "                    continue\n",
    "            for k in range(0, len(attribute_two_words)):\n",
    "                cos2=0\n",
    "                wt = target_two_words[i]\n",
    "                at2 = attribute_two_words[k]\n",
    "                try:\n",
    "                    cos2= model.wv.similarity(wt, at2)\n",
    "                    cos.append(cos2)\n",
    "                    c2.append(cos2)\n",
    "                except:\n",
    "                    cos2=0\n",
    "                    cos.append(cos2)\n",
    "                    c2.append(cos2)\n",
    "                    continue\n",
    "            s2.append((np.mean(c1)-np.mean(c2)))\n",
    "            S.append((np.mean(c1)-np.mean(c2)))\n",
    "    s=np.sum(s1)-np.sum(s2)\n",
    "    stdev=np.std(S)\n",
    "    print(target_one + ' vs ' + target_two  + ' , ' +attribute_one + ' vs ' + attribute_two +', d = ' + str(s/(stdev*n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec using gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(docp,size=100,window=20,min_count=5,workers=10,iter=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weat_test('female_names','male_names', female_names, 'softAttitude' ,'strongAttitude', softAttitude, male_names, strongAttitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(docp, size=100, window=20, min_count=5, workers=4,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weat_test('female_names','male_names', female_names, 'softAttitude' ,'strongAttitude', softAttitude, male_names, strongAttitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support and Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrire lyrics as doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mctr=0\n",
    "for d in docp:\n",
    "    flag=0\n",
    "    for word in male_names:\n",
    "        if word in d:\n",
    "            flag=1\n",
    "    \n",
    "    if flag==1:\n",
    "        mctr=mctr+1\n",
    "mctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fctr=0\n",
    "for d in docp:\n",
    "    flag=0\n",
    "    for word in female_names:\n",
    "        if word in d:\n",
    "            flag=1\n",
    "    \n",
    "    if flag==1:\n",
    "        fctr=fctr+1\n",
    "fctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=0\n",
    "for d in docp:\n",
    "    flag=0\n",
    "    for word in female_names:\n",
    "        for w2 in alcohol:\n",
    "            if word in d:\n",
    "                if w2 in d:\n",
    "                    flag=1\n",
    "        \n",
    "    if flag==1:\n",
    "        ctr=ctr+1\n",
    "        \n",
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att=['color','softAttitude','strongAttitude','cars','clothes','food','alcohol','bodylooks']\n",
    "fem_support=[]\n",
    "male_support=[]\n",
    "fem_confidence=[]\n",
    "male_confidence=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att1=[color,softAttitude,strongAttitude,cars, clothes,food,alcohol,bodylooks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in att1:\n",
    "    ctr=0\n",
    "    for d in docp:\n",
    "        flag=0\n",
    "        for word in female_names:\n",
    "            for w2 in i:\n",
    "                if word in d:\n",
    "                    if w2 in d:\n",
    "                        flag=1\n",
    "        \n",
    "        if flag==1:\n",
    "            ctr=ctr+1\n",
    "    fem_support.append((ctr/total)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in att1:\n",
    "    ctr=0\n",
    "    for d in docp:\n",
    "        flag=0\n",
    "        for word in male_names:\n",
    "            for w2 in i:\n",
    "                if word in d:\n",
    "                    if w2 in d:\n",
    "                        flag=1\n",
    "        \n",
    "        if flag==1:\n",
    "            ctr=ctr+1\n",
    "    male_support.append((ctr/total)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in att1:\n",
    "    ctr=0\n",
    "    for d in docp:\n",
    "        flag=0\n",
    "        for word in female_names:\n",
    "            for w2 in i:\n",
    "                if word in d:\n",
    "                    if w2 in d:\n",
    "                        flag=1\n",
    "        \n",
    "        if flag==1:\n",
    "            ctr=ctr+1\n",
    "    fem_confidence.append((ctr/fctr)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in att1:\n",
    "    ctr=0\n",
    "    for d in docp:\n",
    "        flag=0\n",
    "        for word in male_names:\n",
    "            for w2 in i:\n",
    "                if word in d:\n",
    "                    if w2 in d:\n",
    "                        flag=1\n",
    "        \n",
    "        if flag==1:\n",
    "            ctr=ctr+1\n",
    "    male_confidence.append((ctr/mctr)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support=pd.DataFrame({'attribute':att,'female_names':fem_support,'male_names':male_support})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence=pd.DataFrame({'attribute':att,'female_names':fem_confidence,'male_names':male_confidence})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support confidence on sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sent=[]\n",
    "for i in range(data.shape[0]):\n",
    "    doc_sent.append(re.sub('[^a-zA-z\\s]','',data['songLyrics'][i].lower()).split(\"\\n\"))\n",
    "nonrep_doc=[]\n",
    "for song in doc_sent:\n",
    "    d=[]\n",
    "    for line in song:\n",
    "        if line not in d:\n",
    "            d.append(line)\n",
    "    nonrep_doc.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doca=[]\n",
    "for i in nonrep_doc:\n",
    "    for j in i:\n",
    "        if j =='':\n",
    "            continue\n",
    "        doca.append(nltk.word_tokenize(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doca[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=[]\n",
    "\n",
    "for l in range(len(doca)):\n",
    "    k=[]\n",
    "    for i in range(len(doca[l])):\n",
    "        if doca[l][i] in vocab_d:\n",
    "            k.append(vocab_d[doca[l][i]])\n",
    "        else:\n",
    "            k.append(doca[l][i])\n",
    "    doc1.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mctr=0\n",
    "for d in doc1:\n",
    "    flag=0\n",
    "    for word in male_names:\n",
    "        if word in d:\n",
    "            flag=1\n",
    "    \n",
    "    if flag==1:\n",
    "        mctr=mctr+1\n",
    "fctr=0\n",
    "for d in doc1:\n",
    "    flag=0\n",
    "    for word in female_names:\n",
    "        if word in d:\n",
    "            flag=1\n",
    "    \n",
    "    if flag==1:\n",
    "        fctr=fctr+1\n",
    "mctr,fctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=len(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=0\n",
    "for d in doc1:\n",
    "    flag=0\n",
    "    for word in female_names:\n",
    "        for w2 in alcohol:\n",
    "            if word in d:\n",
    "                if w2 in d:\n",
    "                    flag=1\n",
    "        \n",
    "    if flag==1:\n",
    "        ctr=ctr+1\n",
    "        \n",
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att=['color','softAttitude','strongAttitude','cars','clothes','food','alcohol','bodylooks']\n",
    "fem_support=[]\n",
    "male_support=[]\n",
    "fem_confidence=[]\n",
    "male_confidence=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att1=[color,softAttitude,strongAttitude,cars, clothes,food,alcohol,bodylooks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in att1:\n",
    "    ctr=0\n",
    "    for d in doc1:\n",
    "        flag=0\n",
    "        for word in female_names:\n",
    "            for w2 in i:\n",
    "                if word in d:\n",
    "                    if w2 in d:\n",
    "                        flag=1\n",
    "        \n",
    "        if flag==1:\n",
    "            ctr=ctr+1\n",
    "    fem_support.append((ctr/total)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in att1:\n",
    "    ctr=0\n",
    "    for d in doc1:\n",
    "        flag=0\n",
    "        for word in male_names:\n",
    "            for w2 in i:\n",
    "                if word in d:\n",
    "                    if w2 in d:\n",
    "                        flag=1\n",
    "        \n",
    "        if flag==1:\n",
    "            ctr=ctr+1\n",
    "    male_support.append((ctr/total)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in att1:\n",
    "    ctr=0\n",
    "    for d in doc1:\n",
    "        flag=0\n",
    "        for word in female_names:\n",
    "            for w2 in i:\n",
    "                if word in d:\n",
    "                    if w2 in d:\n",
    "                        flag=1\n",
    "        \n",
    "        if flag==1:\n",
    "            ctr=ctr+1\n",
    "    fem_confidence.append((ctr/fctr)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in att1:\n",
    "    ctr=0\n",
    "    for d in doc1:\n",
    "        flag=0\n",
    "        for word in male_names:\n",
    "            for w2 in i:\n",
    "                if word in d:\n",
    "                    if w2 in d:\n",
    "                        flag=1\n",
    "        \n",
    "        if flag==1:\n",
    "            ctr=ctr+1\n",
    "    male_confidence.append((ctr/mctr)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support1=pd.DataFrame({'attribute':att,'female_names':fem_support,'male_names':male_support})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence1=pd.DataFrame({'attribute':att,'female_names':fem_confidence,'male_names':male_confidence})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support confidence paragraph wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2=[]\n",
    "for i in range(data.shape[0]):\n",
    "    doc2.append(re.sub('[^a-zA-z\\s]','',data['songLyrics'][i].lower()).split(\"\\n\\n\"))\n",
    "doc22=[]\n",
    "for song in doc2:\n",
    "    d=[]\n",
    "    for line in song:\n",
    "        if line not in d:\n",
    "            d.append(line)\n",
    "    doc22.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc222=[]\n",
    "for i in doc22:\n",
    "    for j in i:\n",
    "        doc222.append(j.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doca=[]\n",
    "for i in range(len(doc222)):\n",
    "    doca.append(nltk.word_tokenize(\" \".join(doc222[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=[]\n",
    "\n",
    "for l in range(len(doca)):\n",
    "    k=[]\n",
    "    for i in range(len(doca[l])):\n",
    "        if doca[l][i] in vocab_d:\n",
    "            k.append(vocab_d[doca[l][i]])\n",
    "        else:\n",
    "            k.append(doca[l][i])\n",
    "    doc1.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mctr=0\n",
    "for d in doc1:\n",
    "    flag=0\n",
    "    for word in male_names:\n",
    "        if word in d:\n",
    "            flag=1\n",
    "    \n",
    "    if flag==1:\n",
    "        mctr=mctr+1\n",
    "fctr=0\n",
    "for d in doc1:\n",
    "    flag=0\n",
    "    for word in female_names:\n",
    "        if word in d:\n",
    "            flag=1\n",
    "    \n",
    "    if flag==1:\n",
    "        fctr=fctr+1\n",
    "mctr,fctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=len(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr=0\n",
    "for d in doc1:\n",
    "    flag=0\n",
    "    for word in female_names:\n",
    "        for w2 in alcohol:\n",
    "            if word in d:\n",
    "                if w2 in d:\n",
    "                    flag=1\n",
    "        \n",
    "    if flag==1:\n",
    "        ctr=ctr+1\n",
    "        \n",
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att=['color','softAttitude','strongAttitude','cars','clothes','food','alcohol','bodylooks']\n",
    "fem_support=[]\n",
    "male_support=[]\n",
    "fem_confidence=[]\n",
    "male_confidence=[]\n",
    "att1=[color,softAttitude,strongAttitude,cars, clothes,food,alcohol,bodylooks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in att1:\n",
    "    ctr=0\n",
    "    for d in doc1:\n",
    "        flag=0\n",
    "        for word in female_names:\n",
    "            for w2 in i:\n",
    "                if word in d:\n",
    "                    if w2 in d:\n",
    "                        flag=1\n",
    "        \n",
    "        if flag==1:\n",
    "            ctr=ctr+1\n",
    "    fem_support.append((ctr/total)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in att1:\n",
    "    ctr=0\n",
    "    for d in doc1:\n",
    "        flag=0\n",
    "        for word in male_names:\n",
    "            for w2 in i:\n",
    "                if word in d:\n",
    "                    if w2 in d:\n",
    "                        flag=1\n",
    "        \n",
    "        if flag==1:\n",
    "            ctr=ctr+1\n",
    "    male_support.append((ctr/total)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in att1:\n",
    "    ctr=0\n",
    "    for d in doc1:\n",
    "        flag=0\n",
    "        for word in female_names:\n",
    "            for w2 in i:\n",
    "                if word in d:\n",
    "                    if w2 in d:\n",
    "                        flag=1\n",
    "        \n",
    "        if flag==1:\n",
    "            ctr=ctr+1\n",
    "    fem_confidence.append((ctr/fctr)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in att1:\n",
    "    ctr=0\n",
    "    for d in doc1:\n",
    "        flag=0\n",
    "        for word in male_names:\n",
    "            for w2 in i:\n",
    "                if word in d:\n",
    "                    if w2 in d:\n",
    "                        flag=1\n",
    "        \n",
    "        if flag==1:\n",
    "            ctr=ctr+1\n",
    "    male_confidence.append((ctr/mctr)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support1=pd.DataFrame({'attribute':att,'female_names':fem_support,'male_names':male_support})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence1=pd.DataFrame({'attribute':att,'female_names':fem_confidence,'male_names':male_confidence})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
